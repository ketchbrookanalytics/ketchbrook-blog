[
  {
    "path": "posts/2022-03-13-towards-building-a-dynamic-credit-risk-framework/",
    "title": "Towards Building a Dynamic Credit Risk Framework",
    "description": "Models and systems, systems and models",
    "author": [
      {
        "name": "Michael Thomas",
        "url": {
          "https://www.linkedin.com/in/michaeljthomas2/": {}
        }
      }
    ],
    "date": "2022-03-13",
    "categories": [],
    "contents": "\r\nLast week we discussed some high-level strategies for getting more of your data into your model. This week we are going to dive deeper into the benefits of credit risk modeling frameworks that go beyond the “traditional” (linear/logistic regression, decision trees, etc.) approaches.\r\nThe central problem we are trying to solve today is multi-faceted:\r\n\r\nTo further complicate matters, regulatory requirements such as CECL may lead to modeling probability of default in an entirely different way.\r\nMaking Risk More Dynamic\r\nLet’s envision a world where, instead of disparate models that assess probability of default at the time of certain credit events (e.g., origination, renewal, etc.), we have a single model that estimates PD in real-time.\r\nThis world is not just possible – it’s a framework that Ketchbrook Analytics has spent years developing, and building out for our banking clients.\r\nWhat Do We Have to Gain?\r\nThe value proposition for this framework includes greater flexibility, decreased risk and improved insights. The technical details of the modeling approach allow any organization to:\r\nincorporate new information (new repayment data, new economic outlook data, etc.) about a loan to continuously update it’s predicted probability of default\r\nlook at its portfolio on any given day and understand the current risk for a single loan, a segment of loans, or the entire portfolio\r\nsimulate the impact of a new deal on the portfolio during the underwriting process\r\nFrom a modeling perspective, this means that we want our inputs (predictors) to be the longitudinal attributes about the loan, and the model output to be probability of default.\r\n\r\nEven more specific, our model output should not be a single number – it should instead be a curve that provides us with not just a predicted probability of default, but a probability of default over the life of the loan.\r\nA Basic Example\r\nTake Loan #1234, for example. This five-year term loan just came into our bank today and passed through our model, which returned the following probability of default curve prediction:\r\n\r\n\r\n{\"x\":{\"theme\":\"\",\"tl\":false,\"draw\":true,\"renderer\":\"canvas\",\"events\":[],\"buttons\":[],\"opts\":{\"yAxis\":[{\"show\":true,\"name\":\"\",\"axisLabel\":{\"formatter\":\"function(value, index) {\\n        var fmt = new Intl.NumberFormat('en', {\\\"style\\\":\\\"percent\\\",\\\"minimumFractionDigits\\\":0,\\\"maximumFractionDigits\\\":0,\\\"currency\\\":\\\"USD\\\"});\\n        return fmt.format(value);\\n    }\"}}],\"xAxis\":[{\"data\":[\"2022\",\"2023\",\"2024\",\"2025\",\"2026\"],\"type\":\"category\",\"boundaryGap\":true,\"name\":\"Year\"}],\"legend\":{\"data\":[\"Probability of Default\"],\"show\":false,\"type\":\"plain\"},\"series\":[{\"data\":[{\"value\":[\"2022\",\"0.007503999\"]},{\"value\":[\"2023\",\"0.019517418\"]},{\"value\":[\"2024\",\"0.065092755\"]},{\"value\":[\"2025\",\"0.088780812\"]},{\"value\":[\"2026\",\"0.160179988\"]}],\"yAxisIndex\":0,\"xAxisIndex\":0,\"name\":\"Probability of Default\",\"type\":\"line\",\"coordinateSystem\":\"cartesian2d\",\"areaStyle\":[],\"smooth\":true}],\"title\":[{\"text\":\"Loan #1234 (At Origination)\",\"subtext\":\"Estimated Probability of Default over Lifetime (5-Year Term)\"}],\"tooltip\":{\"trigger\":\"axis\",\"formatter\":\"function(params, ticket, callback) {\\n        var fmt = new Intl.NumberFormat('en', {\\\"style\\\":\\\"percent\\\",\\\"minimumFractionDigits\\\":1,\\\"maximumFractionDigits\\\":1,\\\"currency\\\":\\\"USD\\\"});\\n        var res = params[0].value[0];\\n        for (i = 0; i < params.length; i++) {\\n            res += '<br />' +\\n                   params[i].marker + ' ' +\\n                   params[i].seriesName + ': ' +\\n                   fmt.format(parseFloat(params[i].value[1]));\\n        }\\n        return res;\\n    }\",\"axisPointer\":{\"label\":\"function(params, ticket, callback) {\\n        var fmt = new Intl.NumberFormat('en', {\\\"style\\\":\\\"percent\\\",\\\"minimumFractionDigits\\\":1,\\\"maximumFractionDigits\\\":1,\\\"currency\\\":\\\"USD\\\"});\\n        var res = params[0].value[0];\\n        for (i = 0; i < params.length; i++) {\\n            res += '<br />' +\\n                   params[i].marker + ' ' +\\n                   params[i].seriesName + ': ' +\\n                   fmt.format(parseFloat(params[i].value[1]));\\n        }\\n        return res;\\n    }\"}}},\"dispose\":true},\"evals\":[\"opts.yAxis.0.axisLabel.formatter\",\"opts.tooltip.formatter\",\"opts.tooltip.axisPointer.label\"],\"jsHooks\":[]}\r\n[Tip: You can hover over the chart above – it’s interactive!]\r\nOur model estimates that Loan #1234 has a 0.8% probability of defaulting sometime prior to the end of this year (2022), a 2.0% probability of defaulting between now and the end of 2023, … , and a 16.0% probability of defaulting during its life.\r\nFast-forward two years later, and Loan #1234 has not yet defaulted, with three years remaining on its five-year term. We have new information about this loan that we did not have at origination (e.g., repayment history), as well as updated information (e.g., industry outlook). Running it through our model again, the curve has likely changed:\r\n\r\n\r\n{\"x\":{\"theme\":\"\",\"tl\":false,\"draw\":true,\"renderer\":\"canvas\",\"events\":[],\"buttons\":[],\"opts\":{\"yAxis\":[{\"show\":true,\"name\":\"\",\"axisLabel\":{\"formatter\":\"function(value, index) {\\n        var fmt = new Intl.NumberFormat('en', {\\\"style\\\":\\\"percent\\\",\\\"minimumFractionDigits\\\":0,\\\"maximumFractionDigits\\\":0,\\\"currency\\\":\\\"USD\\\"});\\n        return fmt.format(value);\\n    }\"}}],\"xAxis\":[{\"data\":[\"2024\",\"2025\",\"2026\"],\"type\":\"category\",\"boundaryGap\":true,\"name\":\"Year\"}],\"legend\":{\"data\":[\"Probability of Default\"],\"show\":false,\"type\":\"plain\"},\"series\":[{\"data\":[{\"value\":[\"2024\",\"0.04595530\"]},{\"value\":[\"2025\",\"0.04787393\"]},{\"value\":[\"2026\",\"0.07164692\"]}],\"yAxisIndex\":0,\"xAxisIndex\":0,\"name\":\"Probability of Default\",\"type\":\"line\",\"coordinateSystem\":\"cartesian2d\",\"areaStyle\":[],\"smooth\":true}],\"title\":[{\"text\":\"Loan #1234 (Two Years Later)\",\"subtext\":\"Estimated Probability of Default over Lifetime (5-Year Term)\"}],\"tooltip\":{\"trigger\":\"axis\",\"formatter\":\"function(params, ticket, callback) {\\n        var fmt = new Intl.NumberFormat('en', {\\\"style\\\":\\\"percent\\\",\\\"minimumFractionDigits\\\":1,\\\"maximumFractionDigits\\\":1,\\\"currency\\\":\\\"USD\\\"});\\n        var res = params[0].value[0];\\n        for (i = 0; i < params.length; i++) {\\n            res += '<br />' +\\n                   params[i].marker + ' ' +\\n                   params[i].seriesName + ': ' +\\n                   fmt.format(parseFloat(params[i].value[1]));\\n        }\\n        return res;\\n    }\",\"axisPointer\":{\"label\":\"function(params, ticket, callback) {\\n        var fmt = new Intl.NumberFormat('en', {\\\"style\\\":\\\"percent\\\",\\\"minimumFractionDigits\\\":1,\\\"maximumFractionDigits\\\":1,\\\"currency\\\":\\\"USD\\\"});\\n        var res = params[0].value[0];\\n        for (i = 0; i < params.length; i++) {\\n            res += '<br />' +\\n                   params[i].marker + ' ' +\\n                   params[i].seriesName + ': ' +\\n                   fmt.format(parseFloat(params[i].value[1]));\\n        }\\n        return res;\\n    }\"}}},\"dispose\":true},\"evals\":[\"opts.yAxis.0.axisLabel.formatter\",\"opts.tooltip.formatter\",\"opts.tooltip.axisPointer.label\"],\"jsHooks\":[]}\r\nWe would hope to see a loan with strong repayment history and an improving industry outlook to show less risk across the PD curve. Conversely, we would hope that a loan with multiple past due events and worsening industry outlook would have an updated PD curve that expressed greater risk (i.e., greater probability of default over the remaining life of the loan).\r\nIn the case of Loan #1234, it looks like it has performed pretty well, since the updated probability of defaulting before term is down from 16.0% to 7.2%.\r\nApplication in Practice\r\nIf we want to know the probability of a specific loan (including a new loan, a renewal, or a group of existing loans in a portfolio) defaulting today, we can easily get this by looking at the left-most point on the PD curves above.\r\nIf we want to know the probability of a loan ever defaulting during its life, we can easily get this by looking at the right-most point on the curve.\r\n\r\nFrom a practical perspective, having a modeling framework that provides probability of default estimates at any time (including origination) that updates dynamically as we get new information allows us to quickly build automated loan decisioning, scorecard lending, CECL, and stress testing models.\r\n\r\nInterested in Learning More?\r\nGet in touch with us today at info@ketchbrookanalytics.com\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-03-13T18:24:44-04:00",
    "input_file": "towards-building-a-dynamic-credit-risk-framework.knit.md"
  },
  {
    "path": "posts/2022-02-19-making-small-data-bigger/",
    "title": "Making Small Data Big(ger)",
    "description": "Don't let your model choice shrink your data.",
    "author": [
      {
        "name": "Michael Thomas",
        "url": {}
      }
    ],
    "date": "2022-02-19",
    "categories": [],
    "contents": "\r\nOne of the caveats of working with your traditional vanilla machine learning algorithms (e.g., linear regression, logistic regression, decision trees, etc.) is that each case (row) in your training dataset must be independent. Let’s explore what exactly this means.\r\nThe way those algorithms learn is by looking at a bunch of cases: the circumstances surrounding each case, and what the outcome was for each case. The algorithm then tries to boil all of these cases down to a handful of rules that do a pretty good job at explaining how certain circumstances generally lead to particular outcomes.\r\nApplications in Credit Risk\r\nWhen we think about credit risk models, the cases are perhaps a bunch of historical loans in your portfolio where we know what the outcome was. To provide a simplified example, let’s suppose we are building a logistic regression model where the possible outcomes are (1) the loan was paid back in full or, (2) the borrower defaulted on the loan.\r\n\r\n\r\nLoan ID\r\n\r\n\r\nDebt Coverage Ratio\r\n\r\n\r\nCredit Score\r\n\r\n\r\nIndustry Outlook\r\n\r\n\r\nOutcome\r\n\r\n\r\n1001\r\n\r\n\r\n1.334\r\n\r\n\r\n711\r\n\r\n\r\nFair\r\n\r\n\r\nPaid in Full\r\n\r\n\r\n1002\r\n\r\n\r\n1.163\r\n\r\n\r\n760\r\n\r\n\r\nPoor\r\n\r\n\r\nDefault\r\n\r\n\r\n1003\r\n\r\n\r\n1.858\r\n\r\n\r\n740\r\n\r\n\r\nExcellent\r\n\r\n\r\nPaid in Full\r\n\r\n\r\n1004\r\n\r\n\r\n0.767\r\n\r\n\r\n724\r\n\r\n\r\nPoor\r\n\r\n\r\nPaid in Full\r\n\r\n\r\n1005\r\n\r\n\r\n1.346\r\n\r\n\r\n712\r\n\r\n\r\nAbove Average\r\n\r\n\r\nDefault\r\n\r\n\r\n1006\r\n\r\n\r\n1.966\r\n\r\n\r\n697\r\n\r\n\r\nExcellent\r\n\r\n\r\nPaid in Full\r\n\r\n\r\n1007\r\n\r\n\r\n1.502\r\n\r\n\r\n671\r\n\r\n\r\nExcellent\r\n\r\n\r\nDefault\r\n\r\n\r\n1008\r\n\r\n\r\n1.117\r\n\r\n\r\n743\r\n\r\n\r\nFair\r\n\r\n\r\nPaid in Full\r\n\r\n\r\nIn order to create the above dataset to train our model, we had to aggregate each loan into a single observation, so that each row represents a unique loan. Remember, each case in our training data must be independent; for us this means that we cannot have any loan appear more than once. There are many approaches to doing this aggregation which we won’t cover today, but for now just remember that the approach taken should be driven by what information will be available at the time of scoring a new loan.\r\nAggregation is Limiting\r\nWhen we take the step of aggregating our data into unique loan-level observations, we are naturally reducing the amount of data we have to work with. If you have tons of data, this isn’t an issue. But one issue we run into often is severe class imbalance in our outcome. In other words, we tend to have a lot more “Paid in Full” cases than we have “Default” cases.\r\n\r\n“Remember, each case in our training data must be independent; for us this means that we cannot have any loan appear more than once.”\r\n\r\nBut what if we didn’t have to satisfy that independence assumption? What if we didn’t have to aggregate our data? After all, the original data in our database probably looks a lot more like this:\r\n\r\n\r\nLoan ID\r\n\r\n\r\nDate\r\n\r\n\r\nDebt Coverage Ratio\r\n\r\n\r\nCredit Score\r\n\r\n\r\nIndustry Outlook\r\n\r\n\r\nStatus\r\n\r\n\r\n1001\r\n\r\n\r\n2021-06-01\r\n\r\n\r\n1.925\r\n\r\n\r\n749\r\n\r\n\r\nExcellent\r\n\r\n\r\nCurrent\r\n\r\n\r\n1001\r\n\r\n\r\n2021-07-01\r\n\r\n\r\n1.674\r\n\r\n\r\n705\r\n\r\n\r\nGood\r\n\r\n\r\nCurrent\r\n\r\n\r\n1001\r\n\r\n\r\n2021-08-01\r\n\r\n\r\n1.334\r\n\r\n\r\n711\r\n\r\n\r\nFair\r\n\r\n\r\nPaid in Full\r\n\r\n\r\n1002\r\n\r\n\r\n2021-02-01\r\n\r\n\r\n1.199\r\n\r\n\r\n764\r\n\r\n\r\nGood\r\n\r\n\r\nCurrent\r\n\r\n\r\n1002\r\n\r\n\r\n2021-03-01\r\n\r\n\r\n1.163\r\n\r\n\r\n760\r\n\r\n\r\nPoor\r\n\r\n\r\nDefault\r\n\r\n\r\n1003\r\n\r\n\r\n2021-09-01\r\n\r\n\r\n0.644\r\n\r\n\r\n800\r\n\r\n\r\nAbove Average\r\n\r\n\r\nCurrent\r\n\r\n\r\n1003\r\n\r\n\r\n2021-10-01\r\n\r\n\r\n2.654\r\n\r\n\r\n728\r\n\r\n\r\nGood\r\n\r\n\r\nCurrent\r\n\r\n\r\n1003\r\n\r\n\r\n2021-11-01\r\n\r\n\r\n1.858\r\n\r\n\r\n740\r\n\r\n\r\nExcellent\r\n\r\n\r\nPaid in Full\r\n\r\n\r\nThis type of data is sometimes referred to as “longitudinal” data, and represents observations of the same subject(s) over multiple points in time. In our case, the “subjects” are the unique loans. Clearly, the rows in this type of dataset are not independent, since we see the same loan appear more than once.\r\nWhat’s to be Gained\r\nSuppose the independence condition didn’t exist, and we could use this longitudinal data to build our logistic regression model. What would we gain by doing so?\r\nMore Data: For starters, we would have a lot more data! In situations where we don’t have a ton of data to begin with, each row of data we do have is really important. Especially when we have class imbalance in our data – we need as much information about “Default” loans as possible to help our model develop those general rules (and avoid overfitting).\r\nMore Signal: Second, we can give our model insight into a loan’s history in a way that we weren’t able to with our aggregated dataset. For example, it’s probably important to distinguish between a loan that defaulted after being on the books for 3 years versus one that defaulted after 3 months. You can think of this as incorporating an entire additional predictor variable into our model.\r\nEnter: Multi-Level Models\r\nLuckily for us data scientists, we know that we have a lot more tools in our toolbox than just the three algorithms mentioned at the beginning of this article. One suite of lesser-known algorithms we might explore are multi-level models.\r\nIf you haven’t heard of multi-level models, you may be familiar with “mixed effects” or “hierarchical” models. These three terms all refer to roughly the same thing. The big advantage of this type of model? Each case in your training data does not have to be independent. This means that we can use a dataset that looks a lot more like the second table above, as opposed to the (aggregated) first table.\r\nAnalogous Algorithms\r\nFortunately for us, a lot of the more traditional algorithms have multi-level analogs.\r\nAustin Powers Scene, “We’re Not So Different, You and I”In fact, there are multi-level and mixed effects flavors of logistic regression that allow you to accommodate dependence between rows in your training data.\r\nIn our next blog post, we will dive deeper into the technical approaches to implementing these kinds of algorithms for building better credit risk models.\r\nInterested in Learning More?\r\nGet in touch with us today at info@ketchbrookanalytics.com\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-19-making-small-data-bigger/preview.jpeg",
    "last_modified": "2022-02-20T13:06:50-05:00",
    "input_file": {}
  }
]
